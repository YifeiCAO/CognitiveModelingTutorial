---
title: "Code for Modeling"
author: "Yifei Cao"
date: "12/7/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## From Words to Models

Building a random-walk model

```{r}
# Chapter 2, random-walk model
nreps <- 10000 # number of random walks
nsamples <- 2000 # number of times that evidence is being sampled for each decision

drift <- 0.03 # drift rate, the amount of evidence that is available during sampling
sdrw <- 0.3 # standard deviation of the distribution from which we will sample the evidence
criterion <- 3 # distance of the two boundaries

latencies <- rep(0,nreps) 
responses <- rep(0,nreps)
evidence <- matrix(0,nreps,nsamples+1)

for (i in c(1:nreps)) {
  evidence[i,] <- 
    cumsum(c(0,rnorm(nsamples,drift,sdrw))) # use of rnorm, drawing nsamples observations from a normal distribution with mean drift and sd sdrw
  p <- which(abs(evidence[i,])>criterion)[1] # when randomwalk crossed a response boundary, assign to p
  responses[i] <- sign(evidence[i,p]) # evaluate the sign of the evidence where the response was associated with top or bottom boundary
  latencies[i] <- p # p will be recorded as the ith observation in latencies
}
```

And plot the up to 5 random-walk paths, and the histograms of latencies
```{r, fig.height=7}
#plot up to 5 random-walk paths
tbpn <- min(nreps,5)
plot(1:max(latencies[1:tbpn]) + 10, type = "n",las = 1,
     ylim = c(-criterion - 0.5, criterion + 0.5),
     ylab = "Evidence", xlab = "Decision time")
for (i in c(1:tbpn)) {
  lines(evidence[i,1:(latencies[i] - 1)])
}
abline(h = c(criterion,-criterion),lty = "dashed")

#plot histograms of latencies
par(mfrow=c(2,1))
toprt <- latencies[responses>0]
topprop <- length(toprt)/nreps
hist(toprt,col='gray',
     xlab='Decision time', xlim=c(0,max(latencies)),
     main=paste('Top responses (',as.numeric(topprop),
                ') m=',as.character(signif(mean(toprt),4)),
                sep=''),las=1)
botrt <- latencies[responses<0]
botprop <- length(toprt)/nreps
hist(botrt,col='gray',
     xlab='Decision time', xlim=c(0,max(latencies)),
     main=paste('Top responses (',as.numeric(botprop),
                ') m=',as.character(signif(mean(botrt),4)),
                sep=''),las=1)
```

Now add trial-to-trial variability of the starting value of the random-walk and the drift rate. Firstly, lets introduce variability to starting value. Setting the trial-to-trial variability of starting point to 0.8. And we could see that errors became faster, because with the same drift rate, starting point below zero is more possible to reach bottom and thus faster to reach bottom. While this reverse effect also happens on tops (above 0 sp causes faster correct), but have been averaged by other correct trials.
```{r, echo=FALSE, fig.height=7}
nreps <- 1000 # number of random walks
nsamples <- 2000 # number of times that evidence is being sampled for each decision

drift <- 0.03 # drift rate, the amount of evidence that is available during sampling
sdrw <- 0.3 # standard deviation of the distribution from which we will sample the evidence
criterion <- 3 # distance of the two boundaries
t2tsd <- c(0.8, 0.0)

latencies <- rep(0,nreps) 
responses <- rep(0,nreps)
evidence <- matrix(0,nreps,nsamples+1)

for (i in c(1:nreps)) {
  sp <- rnorm(1,0,t2tsd[1])
  dr <- rnorm(1,drift,t2tsd[2])
  evidence[i,] <- 
    cumsum(c(sp,rnorm(nsamples,drift,sdrw))) # use of rnorm, drawing nsamples observations from a normal distribution with mean drift and sd sdrw
  p <- which(abs(evidence[i,])>criterion)[1] # when randomwalk crossed a response boundary, assign to p
  responses[i] <- sign(evidence[i,p]) # evaluate the sign of the evidence where the response was associated with top or bottom boundary
  latencies[i] <- p # p will be recorded as the ith observation in latencies
}

#plot histograms of latencies
par(mfrow=c(2,1))
toprt <- latencies[responses>0]
topprop <- length(toprt)/nreps
hist(toprt,col='gray',
     xlab='Decision time', xlim=c(0,max(latencies)),
     main=paste('Top responses (',as.numeric(topprop),
                ') m=',as.character(signif(mean(toprt),4)),
                sep=''),las=1)
botrt <- latencies[responses<0]
botprop <- length(botrt)/nreps
hist(botrt,col='gray',
     xlab='Decision time', xlim=c(0,max(latencies)),
     main=paste('Bottom responses (',as.numeric(botprop),
                ') m=',as.character(signif(mean(botrt),4)),
                sep=''),las=1)
```
Now make the drift rate a trial-to-trial variability, and with 0.03 positive rate and 0.025 variability. This time errors become slower. Because different drift rate causes different latencies, while drift rates that lead to faster responses will preferentially yield correct responses rather than errors and vice versa.
```{r, echo=FALSE, fig.height=7}
nreps <- 1000 # number of random walks
nsamples <- 2000 # number of times that evidence is being sampled for each decision

drift <- 0.03 # drift rate, the amount of evidence that is available during sampling
sdrw <- 0.3 # standard deviation of the distribution from which we will sample the evidence
criterion <- 3 # distance of the two boundaries
t2tsd <- c(0.0, 0.025)

latencies <- rep(0,nreps) 
responses <- rep(0,nreps)
evidence <- matrix(0,nreps,nsamples+1)

for (i in c(1:nreps)) {
  sp <- rnorm(1,0,t2tsd[1])
  dr <- rnorm(1,drift,t2tsd[2])
  evidence[i,] <- 
    cumsum(c(sp,rnorm(nsamples,drift,sdrw))) # use of rnorm, drawing nsamples observations from a normal distribution with mean drift and sd sdrw
  p <- which(abs(evidence[i,])>criterion)[1] # when randomwalk crossed a response boundary, assign to p
  responses[i] <- sign(evidence[i,p]) # evaluate the sign of the evidence where the response was associated with top or bottom boundary
  latencies[i] <- p # p will be recorded as the ith observation in latencies
}

#plot histograms of latencies
par(mfrow=c(2,1))
toprt <- latencies[responses>0]
topprop <- length(toprt)/nreps
hist(toprt,col='gray',
     xlab='Decision time', xlim=c(0,max(latencies)),
     main=paste('Top responses (',as.numeric(topprop),
                ') m=',as.character(signif(mean(toprt),4)),
                sep=''),las=1)
botrt <- latencies[responses<0]
botprop <- length(botrt)/nreps
hist(botrt,col='gray',
     xlab='Decision time', xlim=c(0,max(latencies)),
     main=paste('Bottom responses (',as.numeric(botprop),
                ') m=',as.character(signif(mean(botrt),4)),
                sep=''),las=1)
```

## Basic Parameter Estimation Techniques

### Estimating Regression Parameters

In this part, we are going to perform a parameter estimation progress. The model we use in this part, involving  the two variables in the standard two=parameter model `yi = b0 + b1*xi + ei`. x and y were generated by randomly sampling 20 observations from a normal distribution with mean = 0, sd = 1. The correlation between the two variables was 0.8, and the best fitting  obtained was `yi = -0.11+ 0.74*xi`.

Let's perform the parameter estimation progress in R, and the first step will be data simulation.
```{r}
rho <- 0.8
intercept <- 0.0
ndatapts <- 20

#generate synthetic data
data <- matrix(0, ndatapts, 2)
data[,2] <- rnorm(ndatapts) # values for independent variable x
data[,1] <- rnorm(ndatapts) * sqrt(1.0 - rho^2) + data[,2] * rho + intercept # values for dependent variable y, and made the      correlation determined by rho

#do conventional regression analysis
lm(data[,1] ~ data[,2])

#assign starting values
startparms <- c(-1, 0.2)
names(startparms) <- c("b1", "b0") # add names to the parameters


#obtain parameter estimates
xout <- optim(startparms, rmsd, data1 = data)
```

```{r}
# defining rmsd function
# plot data and current predictions
getregpred <- function(parms, data) {
  getregpred <- parms["b0"] + parms["b1"]*data[,2]
  #wait with drawing a graph until key is pressed
  par(ask = TRUE)
  plot(data[,2], type="n", las=1, ylim=c(-2,2),xlim=c(-2,2), xlab="X", ylab="Y")
  par(ask = FALSE)
  points(data[,2], data[,1], pch=21, bg = "gray")
  lines(data[,2], getregpred, lty='solid')
  
  return(getregpred)
}
#obtain current predictions and compute discrepancy
rmsd <- function(parms, data1) {
  preds <- getregpred(parms, data1)
  rmsd <- sqrt(sum((preds - data1[,1]^2)/length(preds)))
}
```

